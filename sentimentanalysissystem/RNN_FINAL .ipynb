{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac478d17-4b62-4ece-8593-7f8d5c735309",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5eddce6-c407-4656-91b3-25c88b3091ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Name</th>\n",
       "      <th>Review Date</th>\n",
       "      <th>Airline</th>\n",
       "      <th>Verified</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Type of Traveller</th>\n",
       "      <th>Month Flown</th>\n",
       "      <th>Route</th>\n",
       "      <th>Class</th>\n",
       "      <th>Seat Comfort</th>\n",
       "      <th>Staff Service</th>\n",
       "      <th>Food &amp; Beverages</th>\n",
       "      <th>Inflight Entertainment</th>\n",
       "      <th>Value For Money</th>\n",
       "      <th>Overall Rating</th>\n",
       "      <th>Recommended</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Flight was amazing</td>\n",
       "      <td>Alison Soetantyo</td>\n",
       "      <td>2024-03-01</td>\n",
       "      <td>Singapore Airlines</td>\n",
       "      <td>True</td>\n",
       "      <td>Flight was amazing. The crew onboard this fl...</td>\n",
       "      <td>Solo Leisure</td>\n",
       "      <td>December 2023</td>\n",
       "      <td>Jakarta to Singapore</td>\n",
       "      <td>Business Class</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>seats on this aircraft are dreadful</td>\n",
       "      <td>Robert Watson</td>\n",
       "      <td>2024-02-21</td>\n",
       "      <td>Singapore Airlines</td>\n",
       "      <td>True</td>\n",
       "      <td>Booking an emergency exit seat still meant h...</td>\n",
       "      <td>Solo Leisure</td>\n",
       "      <td>February 2024</td>\n",
       "      <td>Phuket to Singapore</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Food was plentiful and tasty</td>\n",
       "      <td>S Han</td>\n",
       "      <td>2024-02-20</td>\n",
       "      <td>Singapore Airlines</td>\n",
       "      <td>True</td>\n",
       "      <td>Excellent performance on all fronts. I would...</td>\n",
       "      <td>Family Leisure</td>\n",
       "      <td>February 2024</td>\n",
       "      <td>Siem Reap to Singapore</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>“how much food was available</td>\n",
       "      <td>D Laynes</td>\n",
       "      <td>2024-02-19</td>\n",
       "      <td>Singapore Airlines</td>\n",
       "      <td>True</td>\n",
       "      <td>Pretty comfortable flight considering I was f...</td>\n",
       "      <td>Solo Leisure</td>\n",
       "      <td>February 2024</td>\n",
       "      <td>Singapore to London Heathrow</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Title              Name Review Date  \\\n",
       "0                    Flight was amazing  Alison Soetantyo  2024-03-01   \n",
       "1  seats on this aircraft are dreadful      Robert Watson  2024-02-21   \n",
       "2          Food was plentiful and tasty             S Han  2024-02-20   \n",
       "3          “how much food was available          D Laynes  2024-02-19   \n",
       "\n",
       "              Airline Verified  \\\n",
       "0  Singapore Airlines     True   \n",
       "1  Singapore Airlines     True   \n",
       "2  Singapore Airlines     True   \n",
       "3  Singapore Airlines     True   \n",
       "\n",
       "                                             Reviews Type of Traveller  \\\n",
       "0    Flight was amazing. The crew onboard this fl...      Solo Leisure   \n",
       "1    Booking an emergency exit seat still meant h...      Solo Leisure   \n",
       "2    Excellent performance on all fronts. I would...    Family Leisure   \n",
       "3   Pretty comfortable flight considering I was f...      Solo Leisure   \n",
       "\n",
       "     Month Flown                         Route           Class  Seat Comfort  \\\n",
       "0  December 2023          Jakarta to Singapore  Business Class             4   \n",
       "1  February 2024           Phuket to Singapore   Economy Class             5   \n",
       "2  February 2024        Siem Reap to Singapore   Economy Class             1   \n",
       "3  February 2024  Singapore to London Heathrow   Economy Class             5   \n",
       "\n",
       "   Staff Service  Food & Beverages  Inflight Entertainment  Value For Money  \\\n",
       "0              4                 4                       4                4   \n",
       "1              3                 4                       4                1   \n",
       "2              5                 2                       1                5   \n",
       "3              5                 5                       5                5   \n",
       "\n",
       "   Overall Rating Recommended  \n",
       "0               9         yes  \n",
       "1               3          no  \n",
       "2              10         yes  \n",
       "3              10         yes  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv('airlines_reviews.csv')\n",
    "df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e74608c9-2da7-457d-b060-0830e107f72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df['Reviews']\n",
    "y=df['Recommended']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c42b301-b408-4106-a040-6747e17722f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13efb15c-575b-4f9d-ab73-dcd6036eaa63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of x_train (6480,)\n",
      "shape of x_test (1620,)\n",
      "shape of y_train (6480,)\n",
      "shape of y_test (1620,)\n"
     ]
    }
   ],
   "source": [
    "print('shape of x_train',x_train.shape)\n",
    "print('shape of x_test',x_test.shape)\n",
    "print('shape of y_train',y_train.shape)\n",
    "print('shape of y_test',y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e79995e-3809-4d4c-b882-8866ea482bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Boarding process went smoothly, and plane left on time. I had a window seat in the first part of economy section. The plane has 3-4-3 layout. We were 3 adults on this row, and it was very narrow. When the passenger in front of me, reclined his seat, i could hardly look at my screen, and could not fold out the table. The crew told people to raise up the seat backs during the meal times. We had two meals, dinner and breakfast, both meals were ok. I wanted to charge my phone during the flight, usb charger wad not working. I remember many years ago, when travelling with Singapore Airlines, the drink trolley came before the meal, and again when you got the meal, and they showed up again shortly after the meal also. Now you just get drinks along with the meal, and they do not ask if you want a refill. Very ordinary service and not very friendly staff either.\n",
      "no\n"
     ]
    }
   ],
   "source": [
    "print(x_train[6])\n",
    "print(y_train[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dec4e70b-1072-43ca-8c0a-0f04e73eb1ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (24.12.23)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (5.28.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (75.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (1.69.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (3.8.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (2.0.2)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (0.4.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05240cfc-e4c5-4823-9d89-a883b067a49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d3b12bb-d226-434e-917d-88ced5180ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (3.8.0)\n",
      "Requirement already satisfied: absl-py in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from keras) (2.1.0)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from keras) (2.0.2)\n",
      "Requirement already satisfied: rich in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from keras) (13.9.4)\n",
      "Requirement already satisfied: namex in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from keras) (0.0.8)\n",
      "Requirement already satisfied: h5py in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from keras) (3.12.1)\n",
      "Requirement already satisfied: optree in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from keras) (0.14.0)\n",
      "Requirement already satisfied: ml-dtypes in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from keras) (0.4.1)\n",
      "Requirement already satisfied: packaging in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from keras) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from optree->keras) (4.12.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from rich->keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from rich->keras) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abf0c97b-6300-48a5-a621-6e70a4c92d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 19077\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "tokenizer = Tokenizer(num_words=1000, lower=True)  \n",
    "tokenizer.fit_on_texts(x_train) \n",
    "x_train = tokenizer.texts_to_sequences(x_train) \n",
    "x_test = tokenizer.texts_to_sequences(x_test)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1  \n",
    "\n",
    "print(\"Vocabulary size:\", vocab_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d975512-4440-4080-878a-3b8269fcfee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 183, 492, 12, 548, 80, 107, 100, 217, 467, 394, 5, 25, 98, 268, 159, 294, 34, 4, 39, 12, 6, 247, 297, 548, 3, 302, 53, 45, 306, 451, 3, 457, 1, 9, 4, 49, 8, 1, 152, 120, 357, 67, 435, 99, 10]\n",
      "no\n"
     ]
    }
   ],
   "source": [
    "print(x_train[6])\n",
    "print(y_train[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83b776fa-6d27-4140-899f-310b7c5f07cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1  73  32  17   5 145   6 757  10  54 415  21   5  25   2   6 757  11\n",
      " 392   5   4   8 903   8   1 129  24   2 333 392 167  58 130 688   3 656\n",
      "  10   1 173 581   3 108  10 165   1 124   1  26   4 130 321 462 451   3\n",
      "  29 249  12  40 692  19 180  66   1  36 293   4 314  21  16 794   1  34\n",
      " 134   4  39   5 118 405 286 438  12 392  41  44   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0]\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences \n",
    "\n",
    "maxlen = 100 \n",
    "x_train = pad_sequences(x_train, padding='post', maxlen=maxlen) \n",
    "x_test = pad_sequences(x_test, padding='post', maxlen=maxlen)  \n",
    "print(x_train[3, :])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69a96f5c-d1fe-4ed2-a344-41524a125f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6480, 2)\n",
      "[0. 1.]\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "label_mapping = {'no': 0, 'yes': 1}  \n",
    "y_train = y_train.map(label_mapping)  \n",
    "y_test = y_test.map(label_mapping)\n",
    "\n",
    "# Number of classes\n",
    "num_classes = len(label_mapping)\n",
    "\n",
    "# Apply one-hot encoding\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)\n",
    "\n",
    "# Verify shapes and content\n",
    "print(y_train.shape)\n",
    "print(y_train[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "939f4bf2-db18-45ea-9479-8903f291a723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6480, 100, 1)\n",
      "(1620, 100, 1)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, SimpleRNN\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "x_train = np.array(x_train).reshape((x_train.shape[0], x_train.shape[1], 1))\n",
    "print(x_train.shape)  # Example shape: (750, 100, 1)\n",
    "\n",
    "x_test = np.array(x_test).reshape((x_test.shape[0], x_test.shape[1], 1))\n",
    "print(x_test.shape)  # Example shape: (250, 100, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2eaf509-083e-4b2b-b918-ae1748f099b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">953,850</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">29,440</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m50\u001b[0m)        │       \u001b[38;5;34m953,850\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m29,440\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │           \u001b[38;5;34m130\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">983,420</span> (3.75 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m983,420\u001b[0m (3.75 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">983,420</span> (3.75 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m983,420\u001b[0m (3.75 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.layers import Input  # Import Input layer\n",
    "\n",
    "def create_model(vocab_size, embedding_dim, maxlen):\n",
    "  # Create an input layer with the specified shape\n",
    "  inputs = Input(shape=(maxlen,))\n",
    "\n",
    "  # Add the embedding layer\n",
    "  embedding_layer = Embedding(input_dim=vocab_size, \n",
    "                             output_dim=embedding_dim)(inputs)\n",
    "\n",
    "  lstm_layer = LSTM(64, dropout=0.2, recurrent_dropout=0.2)(embedding_layer)\n",
    "  dense_layer = Dense(2, activation='softmax')(lstm_layer)\n",
    "\n",
    "  # Create the model\n",
    "  model = tf.keras.Model(inputs=inputs, outputs=dense_layer)\n",
    "\n",
    "  # Print model summary\n",
    "  model.summary()\n",
    "\n",
    "  # Compile the model\n",
    "  model.compile(loss='categorical_crossentropy', \n",
    "                optimizer='adam', \n",
    "                metrics=['accuracy'])\n",
    "\n",
    "  return model\n",
    "vocab_size = len(tokenizer.word_index) + 1 \n",
    "embedding_dim = 50\n",
    "maxlen = 100\n",
    "\n",
    "# Create the model\n",
    "model = create_model(vocab_size, embedding_dim, maxlen) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a73dc19-7a99-4965-bcc6-38a5b6d4ecc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 56ms/step - accuracy: 0.5723 - loss: 0.6719 - val_accuracy: 0.7623 - val_loss: 0.5452\n",
      "Epoch 2/10\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 58ms/step - accuracy: 0.8041 - loss: 0.4832 - val_accuracy: 0.8568 - val_loss: 0.3952\n",
      "Epoch 3/10\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 57ms/step - accuracy: 0.8196 - loss: 0.4471 - val_accuracy: 0.7395 - val_loss: 0.5610\n",
      "Epoch 4/10\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 58ms/step - accuracy: 0.7520 - loss: 0.5374 - val_accuracy: 0.7253 - val_loss: 0.5690\n",
      "Epoch 5/10\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 58ms/step - accuracy: 0.7344 - loss: 0.5445 - val_accuracy: 0.8235 - val_loss: 0.4433\n",
      "Epoch 6/10\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 56ms/step - accuracy: 0.7544 - loss: 0.5462 - val_accuracy: 0.7259 - val_loss: 0.5365\n",
      "Epoch 7/10\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 57ms/step - accuracy: 0.7423 - loss: 0.5138 - val_accuracy: 0.7469 - val_loss: 0.4896\n",
      "Epoch 8/10\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 58ms/step - accuracy: 0.7637 - loss: 0.4827 - val_accuracy: 0.6889 - val_loss: 0.5199\n",
      "Epoch 9/10\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 57ms/step - accuracy: 0.7037 - loss: 0.5246 - val_accuracy: 0.7704 - val_loss: 0.4291\n",
      "Epoch 10/10\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 59ms/step - accuracy: 0.7898 - loss: 0.4519 - val_accuracy: 0.8358 - val_loss: 0.4378\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x291c977d0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=64, validation_data=(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a0516b71-3641-40c3-a24b-a411a08c09a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8105 - loss: 0.4693\n",
      "Test Loss: 0.43784183263778687\n",
      "Test Accuracy: 0.8358024954795837\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print(f'Test Loss: {loss}')\n",
    "print(f'Test Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db641573-af52-4565-b4f4-56d447f11eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step\n",
      "Predicted sentiment class: 0\n"
     ]
    }
   ],
   "source": [
    "a = [\"The food was absolutely  not delicious  !\"]\n",
    "# Tokenize and pad the example input\n",
    "a = tokenizer.texts_to_sequences(a)\n",
    "a = pad_sequences(a, padding='post', maxlen=maxlen)\n",
    "\n",
    "# Predict the sentiment for the example input\n",
    "prediction = model.predict(a)\n",
    "\n",
    "# Print the prediction (0 means negative, 1 means positive)\n",
    "predicted_class = np.argmax(prediction, axis=1)\n",
    "print(f\"Predicted sentiment class: {predicted_class[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a31e9b1-a20d-4c2f-97a5-9730c49e4bd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9784e95-5312-4ddc-9fda-2e6d05c2525b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b4657c-5d50-43cf-b4d1-393069675bea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17996bb-160b-44f5-a04e-9c33aa725a8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78521bbe-7928-4ac8-9a8e-a30538e6fa2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143a81dc-4430-445a-a726-f54f169e6ab8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fd0065-3d13-4e60-b1a6-e5778e01b802",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de26a9a6-6756-42b3-becc-433c1b4eeeae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a14d308-edda-4986-b829-d8ee2db66a73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
